{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7z/lsvtctdd3pz4fhtvppypnv9c0000gp/T/ipykernel_62188/3105211664.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer # Used to replace missing values in the dataset\n",
    "from sklearn.compose import ColumnTransformer # Allows to apply different transformations to different columns on the dataset.\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler # These classes are used for preprocessing the data before training a machine learning model.\n",
    "from sklearn.model_selection import train_test_split #  used to split the dataset into training and testing sets.\n",
    "from sklearn.naive_bayes import GaussianNB # Used to train a Naive Bayes model.\n",
    "from sklearn.metrics import accuracy_score, classification_report # Used to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>hospital_death</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>hospital_admit_source</th>\n",
       "      <th>icu_admit_source</th>\n",
       "      <th>...</th>\n",
       "      <th>aids</th>\n",
       "      <th>cirrhosis</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>apache_3j_bodysystem</th>\n",
       "      <th>apache_2_bodysystem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.73</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>180.3</td>\n",
       "      <td>Floor</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Cardiovascular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Floor</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Respiratory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.95</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>172.7</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>Metabolic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22.64</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>165.1</td>\n",
       "      <td>Operating Room</td>\n",
       "      <td>Operating Room / Recovery</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>Cardiovascular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>188.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Trauma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hospital_id  hospital_death   age    bmi  elective_surgery  ethnicity  \\\n",
       "0          118               0  68.0  22.73                 0  Caucasian   \n",
       "1           81               0  77.0  27.42                 0  Caucasian   \n",
       "2          118               0  25.0  31.95                 0  Caucasian   \n",
       "3          118               0  81.0  22.64                 1  Caucasian   \n",
       "4           33               0  19.0    NaN                 0  Caucasian   \n",
       "\n",
       "  gender  height hospital_admit_source           icu_admit_source  ...  aids  \\\n",
       "0      M   180.3                 Floor                      Floor  ...   0.0   \n",
       "1      F   160.0                 Floor                      Floor  ...   0.0   \n",
       "2      F   172.7  Emergency Department       Accident & Emergency  ...   0.0   \n",
       "3      F   165.1        Operating Room  Operating Room / Recovery  ...   0.0   \n",
       "4      M   188.0                   NaN       Accident & Emergency  ...   0.0   \n",
       "\n",
       "  cirrhosis diabetes_mellitus  hepatic_failure  immunosuppression  leukemia  \\\n",
       "0       0.0               1.0              0.0                0.0       0.0   \n",
       "1       0.0               1.0              0.0                0.0       0.0   \n",
       "2       0.0               0.0              0.0                0.0       0.0   \n",
       "3       0.0               0.0              0.0                0.0       0.0   \n",
       "4       0.0               0.0              0.0                0.0       0.0   \n",
       "\n",
       "   lymphoma  solid_tumor_with_metastasis  apache_3j_bodysystem  \\\n",
       "0       0.0                          0.0                Sepsis   \n",
       "1       0.0                          0.0           Respiratory   \n",
       "2       0.0                          0.0             Metabolic   \n",
       "3       0.0                          0.0        Cardiovascular   \n",
       "4       0.0                          0.0                Trauma   \n",
       "\n",
       "   apache_2_bodysystem  \n",
       "0       Cardiovascular  \n",
       "1          Respiratory  \n",
       "2            Metabolic  \n",
       "3       Cardiovascular  \n",
       "4               Trauma  \n",
       "\n",
       "[5 rows x 184 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds4 = pd.read_csv('dataset4.csv').drop(columns=[\"encounter_id\", \"patient_id\"])\n",
    "ds4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h1_bilirubin_max        92.265001\n",
       "h1_bilirubin_min        92.265001\n",
       "h1_lactate_min          91.992411\n",
       "h1_lactate_max          91.992411\n",
       "h1_albumin_max          91.398166\n",
       "h1_albumin_min          91.398166\n",
       "h1_pao2fio2ratio_min    87.441257\n",
       "h1_pao2fio2ratio_max    87.441257\n",
       "h1_arterial_ph_min      83.329517\n",
       "h1_arterial_ph_max      83.329517\n",
       "h1_hco3_min             82.969699\n",
       "h1_hco3_max             82.969699\n",
       "h1_arterial_pco2_min    82.822501\n",
       "h1_arterial_pco2_max    82.822501\n",
       "h1_wbc_max              82.815958\n",
       "h1_wbc_min              82.815958\n",
       "h1_arterial_po2_max     82.807236\n",
       "h1_arterial_po2_min     82.807236\n",
       "h1_calcium_min          82.717826\n",
       "h1_calcium_max          82.717826\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = ds4.isnull().sum() # Returns the number of missing values for each column\n",
    "missing_values = missing_values[missing_values > 0] # Removes columns with no missing values.\n",
    "missing_values_percentage = missing_values / len(ds4) * 100 # Calculate percentage of missing values\n",
    "missing_values_percentage_sorted = missing_values_percentage.sort_values(ascending=False) # Sort by percentage descending\n",
    "missing_values_percentage_sorted.head(20)  # Display top 10 columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating numeric and categorical columns\n",
    "numeric_columns = ds4.select_dtypes(include=['number']).columns\n",
    "categorical_columns = ds4.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Imputing numeric columns with median\n",
    "numeric_data = ds4[numeric_columns]\n",
    "imputer_numeric = SimpleImputer(strategy='median') # Median strategy to impute missing values in numeric columns.\n",
    "numeric_data_imputed = pd.DataFrame(imputer_numeric.fit_transform(numeric_data), columns=numeric_columns)\n",
    "\n",
    "# Imputing categorical columns with mode (most frequent)\n",
    "categorical_data = ds4[categorical_columns]\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "categorical_data_imputed = pd.DataFrame(imputer_categorical.fit_transform(categorical_data), columns=categorical_columns)\n",
    "\n",
    "# Merging numeric and categorical data back together\n",
    "data_preprocessed = pd.concat([numeric_data_imputed, categorical_data_imputed], axis=1)\n",
    "\n",
    "# Checking if all missing values are addressed\n",
    "data_preprocessed.isnull().sum().max()  # should be 0 if no missing values remain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Train-Test Splitting for Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((73370, 235), (18343, 235), (73370,), (18343,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_preprocessed[\"hospital_death\"]  # Target variable\n",
    "X = data_preprocessed.drop(\"hospital_death\", axis=1)  # Features\n",
    "\n",
    "# Defining numeric and categorical column indices\n",
    "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Defining the column transformer with one-hot encoding for categorical variables and scaling for numeric variables\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t('num', StandardScaler(), numeric_columns), # standardize the numeric features.\n",
    "\t\t('cat', OneHotEncoder(), categorical_columns) #  encode categorical variables using one-hot encoding.\n",
    "\t],\n",
    "\tremainder='passthrough'  # Pass through any columns not specified in transformers\n",
    ")\n",
    "\n",
    "# Applying the transformations\n",
    "X_processed = preprocessor.fit_transform(X) # transformation scales numeric features and encodes categorical features\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Displaying the shapes of the train and test sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb_model = gnb.fit(X_train, y_train)\n",
    "y_pred = gnb_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8132802704028785"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>13918</td>\n",
       "      <td>2838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>587</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0.0   1.0\n",
       "Actual                \n",
       "0.0        13918  2838\n",
       "1.0          587  1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.959531</td>\n",
       "      <td>0.830628</td>\n",
       "      <td>0.890439</td>\n",
       "      <td>16756.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.260552</td>\n",
       "      <td>0.630120</td>\n",
       "      <td>0.368664</td>\n",
       "      <td>1587.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.813280</td>\n",
       "      <td>0.813280</td>\n",
       "      <td>0.813280</td>\n",
       "      <td>0.81328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.610042</td>\n",
       "      <td>0.730374</td>\n",
       "      <td>0.629551</td>\n",
       "      <td>18343.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.899057</td>\n",
       "      <td>0.813280</td>\n",
       "      <td>0.845296</td>\n",
       "      <td>18343.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0.0            0.959531  0.830628  0.890439  16756.00000\n",
       "1.0            0.260552  0.630120  0.368664   1587.00000\n",
       "accuracy       0.813280  0.813280  0.813280      0.81328\n",
       "macro avg      0.610042  0.730374  0.629551  18343.00000\n",
       "weighted avg   0.899057  0.813280  0.845296  18343.00000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the classification report as a dataframe\n",
    "classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "df_classification_rep = pd.DataFrame(classification_rep)\n",
    "df_report = pd.DataFrame(classification_rep).transpose()\n",
    "df_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
